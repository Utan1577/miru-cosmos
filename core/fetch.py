import requests
import re
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36",
    "Accept-Language": "ja,en-US;q=0.9"
}

# --- Rakuten (N3/N4) ç”¨ã®è¨­å®š ---
ROUND_HEAD_RE = re.compile(r"å›å·\s*ç¬¬(\d+)å›")
DATE_RE = re.compile(r"\d{4}/\d{2}/\d{2}")

# --- KC (MoneyPlan) ç”¨ã®è¨­å®š ---
KC_BASE_URL = "https://qoochan.money-plan.net/round/{}/"
KC_HISTORY_URL = "https://qoochan.money-plan.net/history/"
FRUIT_MAP = {
    "ãƒªãƒ³ã‚´": "ğŸ", "ãƒŸã‚«ãƒ³": "ğŸŠ", "ãƒ¡ãƒ­ãƒ³": "ğŸˆ", "ãƒ–ãƒ‰ã‚¦": "ğŸ‡", "ãƒ¢ãƒ¢": "ğŸ‘",
    "ã‚Šã‚“ã”": "ğŸ", "ã¿ã‹ã‚“": "ğŸŠ", "ã‚ã‚ã‚“": "ğŸˆ", "ã¶ã©ã†": "ğŸ‡", "ã‚‚ã‚‚": "ğŸ‘"
}

# ---------------------------------------------------------
# Helper Functions
# ---------------------------------------------------------
def get_month_urls(past_url: str):
    try:
        r = requests.get(past_url, headers=HEADERS, timeout=20)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")

        urls = []
        for a in soup.select("a[href]"):
            href = a.get("href")
            if href and re.search(r"/\d{6}/$", href):
                ym = re.search(r"(\d{6})", href).group(1)
                urls.append((ym, urljoin(past_url, href)))

        return sorted(urls, reverse=True)
    except:
        return []

def _extract_payout_from_lines(lines, digits):
    payout = {}
    for i in range(len(lines)):
        t = lines[i]
        if t == "ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ" and i + 2 < len(lines):
            payout["STR"] = {"kuchi": lines[i+1], "yen": lines[i+2]}
        if t == "ãƒœãƒƒã‚¯ã‚¹" and i + 2 < len(lines):
            payout["BOX"] = {"kuchi": lines[i+1], "yen": lines[i+2]}
        if t.startswith("ã‚»ãƒƒãƒˆï¼ˆã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆï¼‰") and i + 2 < len(lines):
            payout["SET-S"] = {"kuchi": lines[i+1], "yen": lines[i+2]}
        if t.startswith("ã‚»ãƒƒãƒˆï¼ˆãƒœãƒƒã‚¯ã‚¹ï¼‰") and i + 2 < len(lines):
            payout["SET-B"] = {"kuchi": lines[i+1], "yen": lines[i+2]}
        if digits == 3 and t == "ãƒŸãƒ‹" and i + 2 < len(lines):
            payout["MINI"] = {"kuchi": lines[i+1], "yen": lines[i+2]}
    return payout

def parse_month_page(url: str, digits: int):
    try:
        r = requests.get(url, headers=HEADERS, timeout=20)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        for tag in soup(["script", "style", "noscript"]):
            tag.decompose()

        text = soup.get_text("\n")
        matches = list(ROUND_HEAD_RE.finditer(text))
        items = []
        
        for idx, m in enumerate(matches):
            round_no = int(m.group(1))
            start = m.start()
            end = matches[idx + 1].start() if idx + 1 < len(matches) else len(text)
            block = text[start:end]

            dm = DATE_RE.search(block)
            dtxt = dm.group(0) if dm else None
            nm = re.search(rf"å½“ã›ã‚“ç•ªå·\s*([0-9]{{{digits}}})", block)
            ntxt = nm.group(1) if nm else None
            block_lines = [l.strip() for l in block.splitlines() if l.strip()]
            payout = _extract_payout_from_lines(block_lines, digits)

            if dtxt and ntxt and re.fullmatch(rf"[0-9]{{{digits}}}", ntxt):
                items.append({
                    "round": round_no,
                    "date": dtxt,
                    "num": ntxt,
                    "payout": payout
                })
        return items
    except:
        return []

# ---------------------------------------------------------
# KC Logic (MoneyPlan)
# ---------------------------------------------------------
def _get_latest_kc_round():
    """å±¥æ­´ãƒšãƒ¼ã‚¸ã‹ã‚‰æœ€æ–°ã®å›å·ã‚’å–å¾—"""
    try:
        r = requests.get(KC_HISTORY_URL, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
        max_round = 0
        for a in soup.find_all("a"):
            text = a.get_text(strip=True)
            m = re.search(r"ç¬¬(\d+)å›", text)
            if m:
                r_num = int(m.group(1))
                if r_num > max_round:
                    max_round = r_num
        return max_round
    except:
        return 0

def fetch_kc_results(need: int = 20):
    """
    ã‚¯ãƒ¼ã¡ã‚ƒã‚“ã®éå»ãƒ‡ãƒ¼ã‚¿ã‚’MoneyPlanã‹ã‚‰å–å¾—
    è©³ç´°ãƒšãƒ¼ã‚¸ã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦ç¢ºå®Ÿã«å–ã‚‹
    """
    latest = _get_latest_kc_round()
    if latest == 0:
        return [], []

    items = []
    used = ["qoochan.money-plan.net"]
    
    # æœ€æ–°å›ã‹ã‚‰æŒ‡å®šå›æ•°åˆ†ã ã‘éå»ã¸é¡ã‚‹
    count = 0
    # è² è·è»½æ¸›ã®ãŸã‚æœ€å¤§30å›ç¨‹åº¦ã¾ã§ãƒã‚§ãƒƒã‚¯
    for i in range(latest, latest - need - 5, -1):
        if i < 1: break
        if count >= need: break
        
        url = KC_BASE_URL.format(i)
        try:
            r = requests.get(url, headers=HEADERS, timeout=5)
            if r.status_code != 200: continue
            
            r.encoding = r.apparent_encoding
            soup = BeautifulSoup(r.text, "html.parser")
            
            # æ­£ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«(class="numbers")ã‚’æ¢ã™
            # ãƒšãƒ¼ã‚¸ä¸‹éƒ¨ã®ç†è«–å€¤ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¿ã‘ã‚‹ãŸã‚ find ã§æœ€åˆã®ä¸€ã¤ã ã‘å–ã‚‹
            target_table = soup.find("table", class_="numbers")
            if not target_table: continue
            
            text = target_table.get_text(" ", strip=True)
            
            # æ—¥ä»˜
            date_str = ""
            m_date = re.search(r"(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)", text)
            if m_date: date_str = m_date.group(1)

            # çµµæŸ„æŠ½å‡º (ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹)
            fruits = []
            matches = re.findall(r"(ãƒªãƒ³ã‚´|ãƒŸã‚«ãƒ³|ãƒ¡ãƒ­ãƒ³|ãƒ–ãƒ‰ã‚¦|ãƒ¢ãƒ¢)", text)
            for m in matches:
                if m in FRUIT_MAP:
                    fruits.append(FRUIT_MAP[m])
            # æœ€åˆã®4ã¤ãŒå½“é¸çµµæŸ„
            result_fruits = fruits[:4]
            if len(result_fruits) != 4: continue
            
            # é‡‘é¡æŠ½å‡º (1ç­‰ï½3ç­‰)
            payout = {}
            for g in ["1ç­‰", "2ç­‰", "3ç­‰"]:
                m_yen = re.search(rf"{g}\D*?([\d,]+)\s*å††", text)
                if m_yen:
                    payout[g] = {"yen": m_yen.group(1) + "å††"}

            items.append({
                "round": i,
                "date": date_str,
                "num": "".join(result_fruits),
                "payout": payout
            })
            count += 1
            
        except:
            continue

    return items, used

# ---------------------------------------------------------
# Main Entry Point
# ---------------------------------------------------------
def fetch_last_n_results(game: str, need: int = 20):
    # KCã®å ´åˆã¯å°‚ç”¨ãƒ­ã‚¸ãƒƒã‚¯ã¸åˆ†å²
    if game == "KC":
        return fetch_kc_results(need)
    
    # N4/N3ã¯æ¥½å¤©ãƒ­ã‚¸ãƒƒã‚¯
    elif game == "N4":
        past = "https://takarakuji.rakuten.co.jp/backnumber/numbers4_past/"
        digits = 4
    elif game == "N3":
        past = "https://takarakuji.rakuten.co.jp/backnumber/numbers3_past/"
        digits = 3
    else:
        # æœªçŸ¥ã®ã‚²ãƒ¼ãƒ ãªã‚‰ç©ºã‚’è¿”ã™
        return [], []

    months = get_month_urls(past)
    collected = {}
    used = []

    for ym, murl in months:
        used.append(ym)
        month_items = parse_month_page(murl, digits)
        for it in month_items:
            collected[it["round"]] = it
        if len(collected) >= need:
            break

    items = sorted(collected.values(), key=lambda x: x["round"], reverse=True)[:need]
    return items, used
